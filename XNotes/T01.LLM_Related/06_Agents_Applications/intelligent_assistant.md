# ğŸ¤– æ™ºèƒ½åŠ©æ‰‹å®ç°

## ğŸ“‹ æ™ºèƒ½åŠ©æ‰‹åŸºç¡€

### ğŸ¯ æ™ºèƒ½åŠ©æ‰‹å®šä¹‰ä¸ä»·å€¼

æ™ºèƒ½åŠ©æ‰‹æ˜¯åŸºäºå¤§æ¨¡å‹çš„åº”ç”¨ç³»ç»Ÿï¼Œèƒ½å¤Ÿç†è§£è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼Œæ‰§è¡Œå„ç±»ä»»åŠ¡ï¼Œå¹¶ä»¥è‡ªç„¶ã€äº¤äº’å¼çš„æ–¹å¼æä¾›å¸®åŠ©ã€‚åœ¨å¤§æ¨¡å‹æ—¶ä»£ï¼Œæ™ºèƒ½åŠ©æ‰‹å·²å‘å±•ä¸ºé›†æˆå¤šç§èƒ½åŠ›çš„ç»¼åˆç³»ç»Ÿã€‚

**æ ¸å¿ƒä»·å€¼**ï¼š
- ğŸ”„ **é«˜æ•ˆä»»åŠ¡å¤„ç†**ï¼šè‡ªåŠ¨åŒ–å®Œæˆé‡å¤æ€§å·¥ä½œ
- ğŸ§  **çŸ¥è¯†è·å–ä¸å’¨è¯¢**ï¼šå¿«é€Ÿæä¾›ä¸“ä¸šé¢†åŸŸä¿¡æ¯
- ğŸ’¼ **ä¸šåŠ¡æµç¨‹è¾…åŠ©**ï¼šèå…¥å·¥ä½œæµç¨‹æå‡æ•ˆç‡
- ğŸ¯ **ä¸ªæ€§åŒ–æœåŠ¡**ï¼šæ ¹æ®ç”¨æˆ·åå¥½æä¾›å®šåˆ¶ä½“éªŒ
- ğŸŒ **å…¨æ¸ é“éƒ¨ç½²**ï¼šåœ¨å¤šç§åœºæ™¯ä¸­æä¾›ä¸€è‡´æœåŠ¡

### ğŸŒŸ æ™ºèƒ½åŠ©æ‰‹ç±»å‹

**æŒ‰èƒ½åŠ›èŒƒå›´åˆ†ç±»**ï¼š
- **é€šç”¨å‹åŠ©æ‰‹**ï¼šå¹¿æ³›é¢†åŸŸçš„å¤šåŠŸèƒ½åŠ©æ‰‹
- **ä¸“ä¸šé¢†åŸŸåŠ©æ‰‹**ï¼šç‰¹å®šé¢†åŸŸçš„æ·±åº¦ä¸“å®¶
- **ä»»åŠ¡å‹åŠ©æ‰‹**ï¼šä¸“æ³¨äºç‰¹å®šä»»åŠ¡çš„æ‰§è¡Œ
- **æ··åˆå‹åŠ©æ‰‹**ï¼šç»“åˆå¤šç§èƒ½åŠ›çš„ç»¼åˆç³»ç»Ÿ

**æŒ‰äº¤äº’æ–¹å¼åˆ†ç±»**ï¼š
- **æ–‡æœ¬äº¤äº’åŠ©æ‰‹**ï¼šåŸºäºæ–‡å­—å¯¹è¯
- **è¯­éŸ³äº¤äº’åŠ©æ‰‹**ï¼šæ”¯æŒè¯­éŸ³è¾“å…¥ä¸è¾“å‡º
- **å¤šæ¨¡æ€åŠ©æ‰‹**ï¼šç»“åˆæ–‡æœ¬ã€è¯­éŸ³ã€å›¾åƒç­‰å¤šç§æ¨¡æ€
- **åµŒå…¥å¼åŠ©æ‰‹**ï¼šèå…¥ç‰¹å®šè½¯ä»¶æˆ–ç³»ç»Ÿä¸­

## ğŸ—ï¸ æ™ºèƒ½åŠ©æ‰‹æ¶æ„è®¾è®¡

### 1. ğŸ“ æ ¸å¿ƒæ¶æ„ç»„ä»¶

å…¸å‹çš„æ™ºèƒ½åŠ©æ‰‹æ¶æ„åŒ…å«ä»¥ä¸‹å…³é”®ç»„ä»¶ï¼š

```
[ç”¨æˆ·ç•Œé¢] âŸ· [å¯¹è¯ç®¡ç†] âŸ· [æ ¸å¿ƒå¤§æ¨¡å‹] âŸ· [å·¥å…·é›†æˆ]
              â†‘              â†“             â†“
        [ç”¨æˆ·çŠ¶æ€ç®¡ç†] âŸ· [çŸ¥è¯†åº“] âŸ· [å®‰å…¨ä¸ç›‘æ§]
```

**æ ¸å¿ƒç»„ä»¶è¯´æ˜**ï¼š

- **ç”¨æˆ·ç•Œé¢**ï¼šè´Ÿè´£ä¸ç”¨æˆ·äº¤äº’çš„å‰ç«¯ç»„ä»¶
- **å¯¹è¯ç®¡ç†**ï¼šå¤„ç†å¤šè½®å¯¹è¯çš„ä¸Šä¸‹æ–‡å’Œæµç¨‹
- **æ ¸å¿ƒå¤§æ¨¡å‹**ï¼šæä¾›æ™ºèƒ½ç†è§£å’Œç”Ÿæˆèƒ½åŠ›
- **å·¥å…·é›†æˆ**ï¼šè¿æ¥å¤–éƒ¨å·¥å…·å’ŒAPIæ‰§è¡Œå®é™…ä»»åŠ¡
- **çŸ¥è¯†åº“**ï¼šå­˜å‚¨å’Œæ£€ç´¢ä¸“ä¸šé¢†åŸŸçŸ¥è¯†
- **ç”¨æˆ·çŠ¶æ€ç®¡ç†**ï¼šè·Ÿè¸ªç”¨æˆ·åå¥½å’Œå†å²
- **å®‰å…¨ä¸ç›‘æ§**ï¼šä¿éšœç³»ç»Ÿå®‰å…¨å’Œè´¨é‡

### 2. ğŸ”„ æ ¸å¿ƒå·¥ä½œæµç¨‹

**åŸºç¡€å¤„ç†æµç¨‹**ï¼š
1. æ¥æ”¶ç”¨æˆ·è¾“å…¥ï¼ˆæ–‡æœ¬/è¯­éŸ³/å›¾åƒï¼‰
2. ç†è§£ç”¨æˆ·æ„å›¾å’Œéœ€æ±‚
3. è§„åˆ’è§£å†³æ–¹æ¡ˆï¼ˆå·¥å…·é€‰æ‹©ï¼‰
4. æ‰§è¡Œå¿…è¦çš„æ“ä½œï¼ˆå·¥å…·è°ƒç”¨ï¼‰
5. ç”Ÿæˆå›å¤å†…å®¹
6. è¿”å›ç»“æœç»™ç”¨æˆ·
7. æ›´æ–°å¯¹è¯çŠ¶æ€å’Œå†å²

**ç¤ºä¾‹å®ç°**ï¼š
```python
def process_user_request(user_input, conversation_context):
    """å¤„ç†ç”¨æˆ·è¯·æ±‚çš„ä¸»æµç¨‹"""
    # 1. æ„å›¾ç†è§£
    intent = understand_intent(user_input, conversation_context)
    
    # 2. å·¥å…·é€‰æ‹©ä¸è§„åˆ’
    tools_to_use, execution_plan = plan_actions(intent, conversation_context)
    
    # 3. å·¥å…·æ‰§è¡Œ
    if tools_to_use:
        tool_results = execute_tools(tools_to_use, execution_plan)
    else:
        tool_results = None
    
    # 4. ç”Ÿæˆå›å¤
    response = generate_response(
        user_input, 
        intent, 
        tool_results, 
        conversation_context
    )
    
    # 5. æ›´æ–°å¯¹è¯çŠ¶æ€
    updated_context = update_conversation_context(
        conversation_context,
        user_input,
        intent,
        tool_results,
        response
    )
    
    return response, updated_context
```

## ğŸ§  æ ¸å¿ƒèƒ½åŠ›å®ç°

### 1. ğŸ” æ„å›¾ç†è§£ä¸ä»»åŠ¡è§„åˆ’

**æ ¸å¿ƒèƒ½åŠ›**ï¼š
- è¯†åˆ«ç”¨æˆ·æ„å›¾
- æå–å…³é”®ä¿¡æ¯
- ç¡®å®šå¿…è¦æ­¥éª¤
- é€‰æ‹©åˆé€‚å·¥å…·

**å®ç°æ–¹æ³•**ï¼š
```python
def understand_intent(user_input, context):
    """ç†è§£ç”¨æˆ·æ„å›¾"""
    prompt = f"""
    åŸºäºä»¥ä¸‹ç”¨æˆ·è¾“å…¥å’Œå¯¹è¯ä¸Šä¸‹æ–‡ï¼Œè¯†åˆ«ç”¨æˆ·æ„å›¾å’Œå…³é”®ä¿¡æ¯ï¼š
    
    ç”¨æˆ·è¾“å…¥: {user_input}
    
    å¯¹è¯å†å²:
    {format_conversation_history(context.history, max_turns=5)}
    
    è¯·è¯†åˆ«ä»¥ä¸‹å†…å®¹:
    1. ä¸»è¦æ„å›¾ (æŸ¥è¯¢ä¿¡æ¯/æ‰§è¡Œæ“ä½œ/åˆ›å»ºå†…å®¹)
    2. å…·ä½“ä»»åŠ¡ç±»å‹
    3. å…³é”®å®ä½“å’Œå‚æ•°
    4. ä»»åŠ¡çº¦æŸæ¡ä»¶
    """
    
    intent_analysis = llm.generate(prompt, temperature=0.1)
    structured_intent = parse_intent_analysis(intent_analysis)
    
    return structured_intent
```

### 2. ğŸ”§ å·¥å…·ä½¿ç”¨èƒ½åŠ›

**å·¥å…·ç±»å‹**ï¼š
- APIè°ƒç”¨å·¥å…·
- æ•°æ®åº“æŸ¥è¯¢å·¥å…·
- å†…å®¹ç”Ÿæˆå·¥å…·
- ä¸“ä¸šé¢†åŸŸå·¥å…·
- ç³»ç»Ÿé›†æˆå·¥å…·

**å·¥å…·è°ƒç”¨å®ç°**ï¼š
```python
def execute_tools(tools_to_use, execution_plan):
    """æ‰§è¡Œå·¥å…·è°ƒç”¨"""
    results = {}
    
    for step in execution_plan:
        tool_name = step["tool"]
        tool_params = step["parameters"]
        
        # è·å–å·¥å…·å®ä¾‹
        tool = get_tool_by_name(tool_name)
        
        # å‚æ•°éªŒè¯
        validated_params = validate_tool_parameters(tool, tool_params)
        
        # æ‰§è¡Œå·¥å…·è°ƒç”¨
        try:
            step_result = tool.execute(**validated_params)
            results[tool_name] = step_result
            
            # å¦‚æœæ­¤æ­¥éª¤çš„ç»“æœéœ€è¦ç”¨äºåç»­æ­¥éª¤
            if "output_mapping" in step:
                for target_step, param_mapping in step["output_mapping"].items():
                    for target_param, source_path in param_mapping.items():
                        # ä»å½“å‰ç»“æœæå–æ•°æ®å¹¶æ›´æ–°åˆ°åç»­æ­¥éª¤çš„å‚æ•°ä¸­
                        value = extract_value_from_path(step_result, source_path)
                        update_parameter_in_plan(
                            execution_plan, 
                            target_step, 
                            target_param, 
                            value
                        )
                        
        except ToolExecutionError as e:
            results[tool_name] = {"error": str(e)}
            
            # å¤„ç†é”™è¯¯ï¼šæ˜¯å¦ç»§ç»­æ‰§è¡Œåç»­æ­¥éª¤
            if not step.get("continue_on_error", False):
                break
    
    return results
```

### 3. ğŸ’¬ å“åº”ç”Ÿæˆä¸ä¼˜åŒ–

**ç”Ÿæˆç­–ç•¥**ï¼š
- ç»“åˆå·¥å…·ç»“æœ
- ä¿æŒå¯¹è¯ä¸€è‡´æ€§
- ç®€æ´ä¸å®Œæ•´å¹³è¡¡
- æ ¼å¼ä¼˜åŒ–ä¸æ’ç‰ˆ

**å®ç°æ–¹æ³•**ï¼š
```python
def generate_response(user_input, intent, tool_results, context):
    """ç”Ÿæˆæœ€ç»ˆå“åº”"""
    prompt = f"""
    åŸºäºä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆå¯¹ç”¨æˆ·çš„å›å¤ï¼š
    
    ç”¨æˆ·è¾“å…¥: {user_input}
    
    ç”¨æˆ·æ„å›¾: {json.dumps(intent, ensure_ascii=False)}
    
    å·¥å…·æ‰§è¡Œç»“æœ: {json.dumps(tool_results, ensure_ascii=False) if tool_results else "æ— å·¥å…·ä½¿ç”¨"}
    
    å¯¹è¯å†å²:
    {format_conversation_history(context.history, max_turns=3)}
    
    è¯·ç”Ÿæˆä¸€ä¸ªæœ‰å¸®åŠ©ã€è‡ªç„¶ä¸”ä¿¡æ¯å®Œæ•´çš„å›å¤ï¼Œè¦æ±‚ï¼š
    1. ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œæ— éœ€é‡è¿°ç”¨æˆ·é—®é¢˜
    2. ç®€æ´æ˜äº†ï¼Œé¿å…ä¸å¿…è¦çš„å®¢å¥—è¯­
    3. å¦‚æœ‰å·¥å…·ä½¿ç”¨ï¼Œç¡®ä¿å‡†ç¡®èå…¥ç»“æœ
    4. å¦‚æœ‰é”™è¯¯ï¼Œæ¸…æ™°è¯´æ˜é—®é¢˜æ‰€åœ¨
    5. ä¿æŒè¯­æ°”ä¸€è‡´æ€§å’Œä¸ªæ€§åŒ–
    """
    
    # ç”Ÿæˆå›å¤
    response_text = llm.generate(
        prompt,
        temperature=0.7,
        max_tokens=1000
    )
    
    # åå¤„ç†ä¼˜åŒ–
    processed_response = post_process_response(response_text, context.user_preferences)
    
    return processed_response
```

### 4. ğŸ“š çŸ¥è¯†åº“é›†æˆ

**çŸ¥è¯†æ¥æº**ï¼š
- å‘é‡æ•°æ®åº“
- ç»“æ„åŒ–æ•°æ®åº“
- çŸ¥è¯†å›¾è°±
- å¤–éƒ¨APIæ•°æ®æº
- ä¼ä¸šå†…éƒ¨æ–‡æ¡£

**æ£€ç´¢å¢å¼ºå®ç°**ï¼š
```python
def retrieve_knowledge(query, context, top_k=5):
    """ä»çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³ä¿¡æ¯"""
    # ç”Ÿæˆæ£€ç´¢æŸ¥è¯¢
    retrieval_query = generate_optimized_query(query, context)
    
    # å‘é‡æ£€ç´¢
    vector_results = vector_db.search(
        query=retrieval_query,
        top_k=top_k * 2  # æ£€ç´¢æ›´å¤šå€™é€‰ï¼Œåç»­è¿‡æ»¤
    )
    
    # ç›¸å…³æ€§è¿‡æ»¤
    filtered_results = filter_by_relevance(vector_results, query, threshold=0.75)
    
    # ç»“æœå»é‡ä¸åˆå¹¶
    unique_results = remove_redundancy(filtered_results)
    
    # é€‰æ‹©æœ€ç»ˆç»“æœ
    final_results = unique_results[:top_k]
    
    # æ•´åˆæ£€ç´¢å†…å®¹
    retrieved_content = format_retrieved_knowledge(final_results)
    
    return {
        "content": retrieved_content,
        "sources": [item.metadata for item in final_results]
    }
```

## ğŸ› ï¸ é«˜çº§åŠ©æ‰‹åŠŸèƒ½

### 1. ğŸ§ª å¤šè½®æ¨ç†ä¸è§„åˆ’

**å…³é”®èƒ½åŠ›**ï¼š
- åˆ†è§£å¤æ‚ä»»åŠ¡
- è®°å¿†ä¸è·Ÿè¸ªçŠ¶æ€
- åŸºäºåé¦ˆè°ƒæ•´
- å¤šæ­¥éª¤æ‰§è¡Œ

**å®ç°ç¤ºä¾‹**ï¼š
```python
def multi_step_reasoning(task, context):
    """æ‰§è¡Œå¤šæ­¥éª¤æ¨ç†"""
    # åˆå§‹åŒ–æ¨ç†è¿‡ç¨‹
    reasoning_steps = []
    current_state = {"task": task, "completed_steps": []}
    
    # è¿­ä»£æ‰§è¡Œç›´åˆ°ä»»åŠ¡å®Œæˆ
    while not is_task_complete(current_state):
        # æ€è€ƒä¸‹ä¸€æ­¥
        next_step = plan_next_step(current_state, context)
        reasoning_steps.append(next_step)
        
        # æ‰§è¡Œæ­¥éª¤
        step_result = execute_reasoning_step(next_step)
        
        # æ›´æ–°çŠ¶æ€
        current_state = update_reasoning_state(
            current_state, 
            next_step, 
            step_result
        )
        
        # é˜²æ­¢æ— é™å¾ªç¯
        if len(reasoning_steps) > MAX_REASONING_STEPS:
            break
    
    # æ•´åˆæ¨ç†ç»“æœ
    final_result = synthesize_reasoning_results(reasoning_steps, current_state)
    
    return final_result, reasoning_steps
```

### 2. ğŸ§© ä¸ªæ€§åŒ–ä¸ä¸Šä¸‹æ–‡ç®¡ç†

**ä¸ªæ€§åŒ–ç»´åº¦**ï¼š
- ç”¨æˆ·åå¥½è®°å¿†
- äº¤äº’å†å²åˆ†æ
- å“åº”é£æ ¼å®šåˆ¶
- ä¸“ä¸šé¢†åŸŸé€‚åº”

**ä¸Šä¸‹æ–‡ç®¡ç†å®ç°**ï¼š
```python
class ConversationContext:
    """å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    def __init__(self, user_id):
        self.user_id = user_id
        self.history = []  # å¯¹è¯å†å²
        self.session_data = {}  # å½“å‰ä¼šè¯æ•°æ®
        self.user_preferences = load_user_preferences(user_id)
        self.active_tasks = []  # è¿›è¡Œä¸­çš„ä»»åŠ¡
        
    def add_exchange(self, user_input, assistant_response, metadata=None):
        """æ·»åŠ ä¸€è½®å¯¹è¯"""
        exchange = {
            "user_input": user_input,
            "assistant_response": assistant_response,
            "timestamp": time.time(),
            "metadata": metadata or {}
        }
        self.history.append(exchange)
        
        # ç»´æŠ¤å†å²é•¿åº¦é™åˆ¶
        if len(self.history) > MAX_HISTORY_LENGTH:
            self.history = self.history[-MAX_HISTORY_LENGTH:]
            
    def update_session_data(self, key, value):
        """æ›´æ–°ä¼šè¯æ•°æ®"""
        self.session_data[key] = value
        
    def get_relevant_history(self, query=None, max_turns=5):
        """è·å–ç›¸å…³å†å²å¯¹è¯"""
        if query and len(self.history) > max_turns:
            # åŸºäºæŸ¥è¯¢é€‰æ‹©æœ€ç›¸å…³çš„å†å²
            relevant_indices = retrieve_relevant_history_indices(
                query, 
                self.history, 
                max_turns
            )
            return [self.history[i] for i in sorted(relevant_indices)]
        else:
            # ç›´æ¥è¿”å›æœ€è¿‘çš„å†å²
            return self.history[-max_turns:]
```

### 3. ğŸ“Š å¤šæ¨¡æ€èƒ½åŠ›

**æ¨¡æ€æ”¯æŒ**ï¼š
- æ–‡æœ¬ç†è§£ä¸ç”Ÿæˆ
- å›¾åƒç†è§£ä¸ç”Ÿæˆ  
- è¯­éŸ³è¯†åˆ«ä¸åˆæˆ
- è§†é¢‘å†…å®¹åˆ†æ
- å¤šæ¨¡æ€èåˆè¾“å‡º

**å®ç°æ€è·¯**ï¼š
```python
def process_multimodal_input(text_input=None, image=None, audio=None):
    """å¤„ç†å¤šæ¨¡æ€è¾“å…¥"""
    results = {}
    
    # å¤„ç†æ–‡æœ¬è¾“å…¥
    if text_input:
        results["text_understanding"] = understand_text(text_input)
    
    # å¤„ç†å›¾åƒè¾“å…¥
    if image is not None:
        # å›¾åƒåˆ†æ
        image_analysis = analyze_image(image)
        results["image_analysis"] = image_analysis
        
        # å¦‚æœåŒæ—¶æœ‰æ–‡æœ¬ï¼Œè¿›è¡Œå¤šæ¨¡æ€èåˆç†è§£
        if text_input:
            results["multimodal_understanding"] = fuse_text_and_image(
                text_input, 
                image_analysis
            )
    
    # å¤„ç†éŸ³é¢‘è¾“å…¥
    if audio is not None:
        # è¯­éŸ³è½¬æ–‡æœ¬
        transcription = speech_to_text(audio)
        results["audio_transcription"] = transcription
        
        # ä½¿ç”¨è½¬å½•æ–‡æœ¬è¿›è¡Œç†è§£
        if not text_input:  # å¦‚æœæ²¡æœ‰ç›´æ¥çš„æ–‡æœ¬è¾“å…¥
            results["text_understanding"] = understand_text(transcription)
    
    # ç»¼åˆç†è§£
    combined_understanding = integrate_multimodal_understanding(results)
    
    return combined_understanding
```

## ğŸ“Š æ™ºèƒ½åŠ©æ‰‹å®ç°åœºæ™¯

### 1. ğŸ‘©â€ğŸ’¼ ä¼ä¸šåä½œåŠ©æ‰‹

**æ ¸å¿ƒåº”ç”¨**ï¼š
- ä¼šè®®åŠ©æ‰‹ä¸è®°å½•
- é¡¹ç›®ç®¡ç†ä¸è·Ÿè¸ª
- æ–‡æ¡£æ™ºèƒ½å¤„ç†
- çŸ¥è¯†ç®¡ç†ä¸æ£€ç´¢

**å®ç°æ•ˆæœ**ï¼š
> "æŸç§‘æŠ€å…¬å¸å¼•å…¥å¤§æ¨¡å‹ä¼ä¸šåŠ©æ‰‹åï¼Œå‘˜å·¥æ–‡æ¡£å¤„ç†æ•ˆç‡æå‡65%ï¼Œä¼šè®®å‡†å¤‡æ—¶é—´å‡å°‘50%ï¼Œæ–°å‘˜å·¥åŸ¹è®­æ—¶é—´ç¼©çŸ­30%ã€‚"

### 2. ğŸ¥ åŒ»ç–—å¥åº·åŠ©æ‰‹

**æ ¸å¿ƒåº”ç”¨**ï¼š
- å¥åº·å’¨è¯¢ä¸å»ºè®®
- åŒ»ç–—çŸ¥è¯†æ£€ç´¢
- å¥åº·æ•°æ®åˆ†æ
- åŒ»æ‚£æ²Ÿé€šè¾…åŠ©

**å®ç°å…³é”®ç‚¹**ï¼š
- åŒ»ç–—çŸ¥è¯†åº“æ„å»º
- ä¸¥æ ¼äº‹å®æ ¸æŸ¥æœºåˆ¶
- å¤šçº§å®‰å…¨å®¡æ ¸
- éšç§æ•°æ®ä¿æŠ¤

### 3. ğŸ“ æ•™è‚²å­¦ä¹ åŠ©æ‰‹

**æ ¸å¿ƒåº”ç”¨**ï¼š
- ä¸ªæ€§åŒ–å­¦ä¹ æŒ‡å¯¼
- ä½œä¸šè¾…å¯¼ä¸åé¦ˆ
- çŸ¥è¯†ç‚¹è§£æ
- å­¦ä¹ è®¡åˆ’åˆ¶å®š

**ä»·å€¼ä½“ç°**ï¼š
- å­¦ä¹ æ•ˆç‡æå‡40-60%
- å­¦ç”Ÿæ»¡æ„åº¦æé«˜85%
- æ•™å¸ˆå·¥ä½œè´Ÿæ‹…å‡è½»35%
- å­¦ä¹ èµ„æºåˆ©ç”¨ç‡æå‡55%

## ğŸ›¡ï¸ å®‰å…¨ä¸ä¼¦ç†è®¾è®¡

### 1. ğŸ”’ å®‰å…¨é˜²æŠ¤æœºåˆ¶

**å®‰å…¨æªæ–½**ï¼š
- è¾“å…¥å†…å®¹å®‰å…¨è¿‡æ»¤
- è¾“å‡ºå†…å®¹å®‰å…¨æ£€æŸ¥
- æ•æ„Ÿä¿¡æ¯è¯†åˆ«ä¸å¤„ç†
- ç”¨æˆ·æƒé™ç®¡ç†ç³»ç»Ÿ
- è¡Œä¸ºç›‘æ§ä¸å®¡è®¡

**å®ç°æ–¹æ³•**ï¼š
```python
def content_safety_check(content, user_context, safety_level="standard"):
    """å†…å®¹å®‰å…¨æ£€æŸ¥"""
    # å®‰å…¨è§„åˆ™é…ç½®
    safety_rules = SAFETY_CONFIGS[safety_level]
    
    # è¿è§„å†…å®¹æ£€æµ‹
    violations = []
    
    # 1. å…³é”®è¯è¿‡æ»¤
    keyword_violations = check_against_keywords(
        content, 
        safety_rules["blocked_keywords"],
        safety_rules["flagged_keywords"]
    )
    violations.extend(keyword_violations)
    
    # 2. æ¨¡å‹æ£€æµ‹
    if safety_rules["use_model_detection"]:
        model_violations = model_based_content_detection(
            content,
            safety_rules["detection_thresholds"]
        )
        violations.extend(model_violations)
    
    # 3. ç‰¹å®šè§„åˆ™æ£€æŸ¥
    rule_violations = check_custom_safety_rules(
        content,
        user_context,
        safety_rules["custom_rules"]
    )
    violations.extend(rule_violations)
    
    # ç»“æœå¤„ç†
    if violations:
        # ç¡®å®šæœ€é«˜ä¸¥é‡çº§åˆ«
        highest_severity = max(v["severity"] for v in violations)
        
        # æ ¹æ®ä¸¥é‡ç¨‹åº¦å†³å®šæ“ä½œ
        if highest_severity >= safety_rules["block_threshold"]:
            return {
                "is_safe": False,
                "action": "block",
                "violations": violations
            }
        elif highest_severity >= safety_rules["flag_threshold"]:
            return {
                "is_safe": False,
                "action": "flag",
                "violations": violations
            }
    
    return {"is_safe": True, "action": "allow"}
```

### 2. ğŸ” é€æ˜åº¦ä¸å¯è§£é‡Šæ€§

**é€æ˜åº¦è®¾è®¡**ï¼š
- åŠ©æ‰‹èƒ½åŠ›æ˜ç¡®è¯´æ˜
- ä¿¡æ¯æ¥æºæ ‡æ³¨
- å·¥å…·ä½¿ç”¨é€æ˜åŒ–
- å†³ç­–è¿‡ç¨‹å¯è¿½æº¯

**å®ç°æ–¹å¼**ï¼š
- å†…å®¹æ¥æºå¼•ç”¨ç³»ç»Ÿ
- æ¨ç†è¿‡ç¨‹è®°å½•
- ç½®ä¿¡åº¦æŒ‡ç¤º
- ç”¨æˆ·åé¦ˆæ”¶é›†

## ğŸ”® å‘å±•è¶‹åŠ¿ä¸å‰æ²¿

### 1. ğŸ§  è‡ªä¸»ä»£ç†åŠ©æ‰‹

**å‰æ²¿ç‰¹ç‚¹**ï¼š
- ä»»åŠ¡åˆ†è§£ä¸è§„åˆ’
- è‡ªä¸»å·¥å…·é€‰æ‹©
- è®°å¿†ä¸å­¦ä¹ èƒ½åŠ›
- è¿­ä»£è‡ªæˆ‘æ”¹è¿›

### 2. ğŸŒ å¤šæ¨¡æ€æ·±åº¦èåˆ

**å‘å±•æ–¹å‘**ï¼š
- å¤šæ¨¡æ€ç†è§£ä¸æ¨ç†
- è·¨æ¨¡æ€çŸ¥è¯†è¿ç§»
- æƒ…å¢ƒæ„ŸçŸ¥èƒ½åŠ›
- æ²‰æµ¸å¼äº¤äº’ä½“éªŒ

### 3. ğŸ”„ ç”Ÿæ€ç³»ç»Ÿé›†æˆ

**æ¼”è¿›è¶‹åŠ¿**ï¼š
- åŠ©æ‰‹é—´åä½œæœºåˆ¶
- ä¸šåŠ¡ç³»ç»Ÿæ·±åº¦æ•´åˆ
- ä¸“ä¸šé¢†åŸŸå®šåˆ¶
- ç”¨æˆ·ç”Ÿæ€å½¢æˆ

## ğŸ“š èµ„æºæ¨è

### 1. ğŸ› ï¸ åŠ©æ‰‹å¼€å‘æ¡†æ¶

- [LangChain](https://github.com/langchain-ai/langchain) - å¤§æ¨¡å‹åº”ç”¨å¼€å‘æ¡†æ¶
- [Auto-GPT](https://github.com/Significant-Gravitas/Auto-GPT) - è‡ªä¸»ä»£ç†ç³»ç»Ÿ
- [Microsoft Semantic Kernel](https://github.com/microsoft/semantic-kernel) - AIåŠ©æ‰‹å¼€å‘SDK
- [CrewAI](https://github.com/joaomdmoura/crewAI) - å¤šä»£ç†åä½œæ¡†æ¶

### 2. ğŸ“‘ å­¦ä¹ èµ„æº

- [æ„å»ºAIåŠ©æ‰‹å®è·µæŒ‡å—](https://www.deeplearning.ai/short-courses/building-systems-with-chatgpt/)
- [åŠ©æ‰‹è®¾è®¡æœ€ä½³å®è·µ](https://platform.openai.com/docs/guides/prompt-engineering)
- [å¤§æ¨¡å‹åº”ç”¨å®‰å…¨](https://www.anthropic.com/index/system-cards-for-claude) 