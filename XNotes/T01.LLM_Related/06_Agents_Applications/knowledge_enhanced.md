# ğŸ“Š çŸ¥è¯†åº“å¢å¼ºåº”ç”¨

## ğŸ“‹ çŸ¥è¯†å¢å¼ºåŸºç¡€

### ğŸ¯ çŸ¥è¯†å¢å¼ºåº”ç”¨ä»·å€¼

å¤§è¯­è¨€æ¨¡å‹åœ¨åŸç”ŸçŸ¥è¯†æ–¹é¢å­˜åœ¨å›ºæœ‰å±€é™æ€§ï¼Œè€ŒçŸ¥è¯†åº“å¢å¼ºåº”ç”¨åˆ™è§£å†³äº†è¿™äº›é—®é¢˜ï¼š

- ğŸ“š **çŸ¥è¯†æ—¶æ•ˆæ€§**ï¼šæ¨¡å‹è®­ç»ƒåçŸ¥è¯†æ— æ³•è‡ªåŠ¨æ›´æ–°
- ğŸ” **ä¸“ä¸šé¢†åŸŸæ·±åº¦**ï¼šé€šç”¨æ¨¡å‹åœ¨ä¸“ä¸šé¢†åŸŸçŸ¥è¯†ä¸å¤Ÿæ·±å…¥
- ğŸ” **å†…éƒ¨ä¿¡æ¯è®¿é—®**ï¼šæ— æ³•ç›´æ¥è®¿é—®ä¼ä¸šç§æœ‰ä¿¡æ¯
- âš ï¸ **äº‹å®å‡†ç¡®æ€§**ï¼šå¯èƒ½äº§ç”Ÿäº‹å®æ€§é”™è¯¯æˆ–"å¹»è§‰"

**çŸ¥è¯†åº“å¢å¼ºæŠ€æœ¯ä¼˜åŠ¿**ï¼š
- ğŸ”„ **å®æ—¶ä¿¡æ¯è®¿é—®**ï¼šè¿æ¥æœ€æ–°ä¿¡æ¯æº
- ğŸ“ **å¯æº¯æºå›ç­”**ï¼šå¼•ç”¨æ¥æºå¢å¼ºå¯ä¿¡åº¦
- ğŸ¢ **ä¼ä¸šçŸ¥è¯†é›†æˆ**ï¼šè¿æ¥å†…éƒ¨æ–‡æ¡£å’Œæ•°æ®
- ğŸ›¡ï¸ **å‡å°‘å¹»è§‰é£é™©**ï¼šåŸºäºäº‹å®ç”Ÿæˆç­”æ¡ˆ
- ğŸ”’ **æ•°æ®éšç§**ï¼šä¿æŒæ•æ„Ÿæ•°æ®åœ¨æœ¬åœ°ç¯å¢ƒ

### ğŸŒŸ ä¸»è¦å®ç°æ–¹å¼

**ä¸¤ç§ä¸»è¦èŒƒå¼**ï¼š

1. **æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)**
   - å®æ—¶ä»å¤–éƒ¨çŸ¥è¯†åº“æ£€ç´¢ä¿¡æ¯
   - å°†æ£€ç´¢ç»“æœèå…¥ç”Ÿæˆä¸Šä¸‹æ–‡
   - çµæ´»ä¸æœ€æ–°ä¿¡æ¯ç»“åˆ
   - æ— éœ€é‡æ–°è®­ç»ƒæ¨¡å‹

2. **çŸ¥è¯†å¾®è°ƒæ¨¡å‹**
   - å°†çŸ¥è¯†ç›´æ¥æ³¨å…¥æ¨¡å‹å‚æ•°
   - ä¸“æ³¨ç‰¹å®šé¢†åŸŸçš„æ·±åº¦é€‚é…
   - æ¨ç†æ—¶ä¸éœ€è¦å®æ—¶æ£€ç´¢
   - éœ€è¦å®šæœŸé‡æ–°è®­ç»ƒæ›´æ–°çŸ¥è¯†

## ğŸ—ï¸ çŸ¥è¯†åº“å¢å¼ºæ¶æ„

### 1. ğŸ“ æ ¸å¿ƒæ¶æ„ç»„ä»¶

å…¸å‹çš„çŸ¥è¯†åº“å¢å¼ºåº”ç”¨åŒ…å«ä»¥ä¸‹å…³é”®ç»„ä»¶ï¼š

```
[å¤–éƒ¨çŸ¥è¯†æº] â†’ [çŸ¥è¯†å¤„ç†ç®¡é“] â†’ [å‘é‡æ•°æ®åº“] â†’ [æ£€ç´¢ç³»ç»Ÿ] â†’ [LLMé›†æˆ] â†’ [ç”¨æˆ·ç•Œé¢]
                   â†‘                              â†“
                [æ›´æ–°æœºåˆ¶] â†â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” [ç”¨æˆ·åé¦ˆ]
```

**ç»„ä»¶åŠŸèƒ½è¯´æ˜**ï¼š

- **å¤–éƒ¨çŸ¥è¯†æº**ï¼šæ–‡æ¡£ã€æ•°æ®åº“ã€APIã€ç½‘é¡µç­‰
- **çŸ¥è¯†å¤„ç†ç®¡é“**ï¼šæ–‡æ¡£åŠ è½½ã€åˆ†å—ã€æ¸…æ´—ã€ç»“æ„åŒ–
- **å‘é‡æ•°æ®åº“**ï¼šçŸ¥è¯†å—çš„é«˜æ•ˆå­˜å‚¨ä¸æ£€ç´¢
- **æ£€ç´¢ç³»ç»Ÿ**ï¼šç›¸ä¼¼åº¦æœç´¢ã€æ··åˆæ£€ç´¢ã€æ’åº
- **LLMé›†æˆ**ï¼šå°†æ£€ç´¢ç»“æœä¸æç¤ºç»“åˆ
- **æ›´æ–°æœºåˆ¶**ï¼šæŒç»­æ›´æ–°çŸ¥è¯†åº“
- **ç”¨æˆ·åé¦ˆ**ï¼šæ”¹è¿›æ£€ç´¢å’Œå›ç­”è´¨é‡

### 2. ğŸ”„ RAGä¸å¾®è°ƒæ¨¡å‹å¯¹æ¯”

**æŠ€æœ¯ç‰¹ç‚¹å¯¹æ¯”**ï¼š

| ç‰¹æ€§ | RAG | çŸ¥è¯†å¾®è°ƒæ¨¡å‹ |
|------|-----|------------|
| çŸ¥è¯†å®æ—¶æ€§ | âœ… é«˜ | âŒ ä½(éœ€é‡æ–°è®­ç»ƒ) |
| éƒ¨ç½²å¤æ‚åº¦ | âš ï¸ ä¸­ç­‰ | âœ… ä½(å•ä¸€æ¨¡å‹) |
| æ¨ç†æˆæœ¬ | âš ï¸ è¾ƒé«˜(æ£€ç´¢+ç”Ÿæˆ) | âœ… ä½(ä»…ç”Ÿæˆ) |
| çŸ¥è¯†é€æ˜åº¦ | âœ… é«˜(å¯æº¯æº) | âŒ ä½(é»‘ç›’) |
| çŸ¥è¯†æ·±åº¦æ•´åˆ | âš ï¸ æµ…å±‚æ•´åˆ | âœ… æ·±åº¦æ•´åˆ |
| çµæ´»æ€§ | âœ… é«˜(æ˜“æ›´æ–°çŸ¥è¯†) | âŒ ä½(éœ€é‡è®­ç»ƒ) |

**é€‚ç”¨åœºæ™¯**ï¼š
- **RAGé€‚åˆ**ï¼šéœ€è¦æœ€æ–°ä¿¡æ¯ã€æº¯æºè¦æ±‚é«˜ã€é¢‘ç¹æ›´æ–°çŸ¥è¯†ã€å¤šé¢†åŸŸæ··åˆåœºæ™¯
- **å¾®è°ƒé€‚åˆ**ï¼šå›ºå®šé¢†åŸŸæ·±åº¦åº”ç”¨ã€æ¨ç†å»¶è¿Ÿæ•æ„Ÿã€è®¡ç®—èµ„æºæœ‰é™åœºæ™¯

## ğŸ’¡ RAGæŠ€æœ¯å®ç°

### 1. ğŸ”– æ–‡æ¡£å¤„ç†

**æ–‡æ¡£åŠ è½½ä¸åˆ†å—**ï¼š
```python
from langchain.document_loaders import DirectoryLoader, PyPDFLoader, TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# åŠ è½½å¤šç§ç±»å‹æ–‡æ¡£
def load_documents(directory_path):
    # PDFæ–‡ä»¶åŠ è½½
    pdf_loader = DirectoryLoader(directory_path, glob="**/*.pdf", loader_cls=PyPDFLoader)
    pdf_docs = pdf_loader.load()
    
    # æ–‡æœ¬æ–‡ä»¶åŠ è½½
    text_loader = DirectoryLoader(directory_path, glob="**/*.txt", loader_cls=TextLoader)
    text_docs = text_loader.load()
    
    # åˆå¹¶æ‰€æœ‰æ–‡æ¡£
    all_docs = pdf_docs + text_docs
    return all_docs

# æ–‡æ¡£åˆ†å—
def split_documents(documents):
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,         # æ¯å—å­—ç¬¦æ•°
        chunk_overlap=200,       # å—é—´é‡å å­—ç¬¦æ•°
        length_function=len,
        separators=["\n\n", "\n", ".", " ", ""]  # ä¼˜å…ˆæŒ‰æ®µè½åˆ†å‰²
    )
    
    chunks = splitter.split_documents(documents)
    return chunks
```

**å†…å®¹æ¸…æ´—ä¸å¼ºåŒ–**ï¼š
- ç§»é™¤æ— ç”¨å…ƒç´ (é¡µçœ‰é¡µè„šã€æ°´å°)
- ç»“æ„åŒ–æå–(æ ‡é¢˜ã€æ®µè½ã€åˆ—è¡¨)
- å…ƒæ•°æ®æ ‡æ³¨(æ¥æºã€æ—¥æœŸã€åˆ†ç±»)
- å†…å®¹å½’ä¸€åŒ–(æ ¼å¼ç»Ÿä¸€ã€ç¼©å†™å±•å¼€)

### 2. ğŸ”¢ å‘é‡åŒ–ä¸å­˜å‚¨

**åµŒå…¥ç”Ÿæˆ**ï¼š
```python
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Chroma, FAISS

def create_vector_store(chunks, embedding_model_name="shibing624/text2vec-base-chinese"):
    # åˆ›å»ºåµŒå…¥æ¨¡å‹
    embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)
    
    # ç”Ÿæˆå‘é‡å­˜å‚¨
    vector_store = FAISS.from_documents(chunks, embeddings)
    
    return vector_store

# åˆ›å»ºå‘é‡æ•°æ®åº“å¹¶æŒä¹…åŒ–
def build_and_save_vectordb(chunks, db_directory):
    embeddings = HuggingFaceEmbeddings(model_name="shibing624/text2vec-base-chinese")
    
    vectordb = Chroma.from_documents(
        documents=chunks,
        embedding=embeddings,
        persist_directory=db_directory
    )
    
    vectordb.persist()  # ä¿å­˜åˆ°ç£ç›˜
    return vectordb
```

**å‘é‡æ•°æ®åº“é€‰æ‹©è€ƒé‡**ï¼š
- **æ•°æ®è§„æ¨¡**ï¼šå°å‹(Chromaã€FAISS)ã€å¤§å‹(Pineconeã€Weaviate)
- **æŸ¥è¯¢æ€§èƒ½**ï¼šå®æ—¶æ€§éœ€æ±‚ã€æ‰¹é‡æ£€ç´¢èƒ½åŠ›
- **éƒ¨ç½²æ–¹å¼**ï¼šæœ¬åœ°éƒ¨ç½²ã€äº‘æœåŠ¡ã€æ··åˆæ¨¡å¼
- **ç‰¹æ®ŠåŠŸèƒ½**ï¼šå…ƒæ•°æ®è¿‡æ»¤ã€å¤šå‘é‡ç´¢å¼•ã€é›†ç¾¤æ”¯æŒ

### 3. ğŸ” æ£€ç´¢æŠ€æœ¯

**ç›¸ä¼¼åº¦æœç´¢**ï¼š
```python
def similarity_search(query, vector_store, k=5):
    """åŸºæœ¬ç›¸ä¼¼åº¦æ£€ç´¢"""
    relevant_docs = vector_store.similarity_search(query, k=k)
    return relevant_docs

def hybrid_search(query, vector_store, keyword_index, k=5, alpha=0.5):
    """æ··åˆæ£€ç´¢ (å‘é‡+å…³é”®è¯)"""
    # å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢
    vector_results = vector_store.similarity_search(query, k=k*2)
    
    # å…³é”®è¯æ£€ç´¢
    keyword_results = keyword_index.search(query, k=k*2)
    
    # ç»“æœèåˆ(åŠ æƒ)
    combined_results = merge_and_rerank(
        vector_results, 
        keyword_results,
        alpha=alpha  # æ§åˆ¶å‘é‡å’Œå…³é”®è¯ç»“æœçš„æƒé‡
    )
    
    return combined_results[:k]
```

**é«˜çº§æ£€ç´¢ç­–ç•¥**ï¼š
- **æŸ¥è¯¢é‡å†™**ï¼šæ‰©å±•ã€æ¾„æ¸…ã€åˆ†è§£å¤æ‚æŸ¥è¯¢
- **å¤šæ­¥æ£€ç´¢**ï¼šå…ˆç²—ç²’åº¦å†ç»†ç²’åº¦æ£€ç´¢
- **ä¸Šä¸‹æ–‡æ„ŸçŸ¥**ï¼šè€ƒè™‘å¯¹è¯å†å²çš„æ£€ç´¢
- **ä¸ªæ€§åŒ–æ£€ç´¢**ï¼šåŸºäºç”¨æˆ·ç”»åƒè°ƒæ•´ç»“æœ

**æ£€ç´¢ä¼˜åŒ–æŠ€æœ¯**ï¼š
```python
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import LLMChainExtractor

def enhanced_retrieval(query, base_retriever, llm):
    """å¢å¼ºæ£€ç´¢(ä½¿ç”¨LLMæå–ç›¸å…³æ®µè½)"""
    # åˆ›å»ºä¸€ä¸ªå‹ç¼©å™¨ï¼Œç”¨äºä»æ£€ç´¢æ–‡æ¡£ä¸­æå–ç›¸å…³éƒ¨åˆ†
    compressor = LLMChainExtractor.from_llm(llm)
    
    # åˆ›å»ºå‹ç¼©æ£€ç´¢å™¨
    compression_retriever = ContextualCompressionRetriever(
        base_compressor=compressor,
        base_retriever=base_retriever
    )
    
    # æ‰§è¡Œå¢å¼ºæ£€ç´¢
    compressed_docs = compression_retriever.get_relevant_documents(query)
    return compressed_docs
```

### 4. ğŸ§© æç¤ºå·¥ç¨‹ä¸é›†æˆ

**RAGæç¤ºæ¨¡æ¿**ï¼š
```python
from langchain.prompts import PromptTemplate

# åŸºç¡€RAGæç¤ºæ¨¡æ¿
rag_prompt_template = """
ä½œä¸ºä¸€ä¸ªçŸ¥è¯†åŠ©æ‰‹ï¼Œè¯·åŸºäºä»¥ä¸‹æä¾›çš„ä¿¡æ¯å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
å¦‚æœæ— æ³•ä»æä¾›çš„ä¿¡æ¯ä¸­æ‰¾åˆ°ç­”æ¡ˆï¼Œè¯·å¦ç‡æ‰¿è®¤ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯ã€‚

ç›¸å…³ä¿¡æ¯:
{context}

ç”¨æˆ·é—®é¢˜: {question}

è¯·æä¾›è¯¦ç»†ä¸”å‡†ç¡®çš„å›ç­”ï¼Œå¹¶åœ¨é€‚å½“çš„æƒ…å†µä¸‹å¼•ç”¨ä¿¡æ¯æ¥æºã€‚
"""

RAG_PROMPT = PromptTemplate(
    input_variables=["context", "question"],
    template=rag_prompt_template
)

# ä½¿ç”¨ç¤ºä¾‹
def generate_rag_response(query, docs, llm):
    # å‡†å¤‡ä¸Šä¸‹æ–‡
    context = "\n\n".join([doc.page_content for doc in docs])
    
    # æ„å»ºå®Œæ•´æç¤º
    prompt = RAG_PROMPT.format(context=context, question=query)
    
    # ç”Ÿæˆå›ç­”
    response = llm.generate(prompt, temperature=0.3)
    return response
```

**é«˜çº§RAGé›†æˆæ–¹æ³•**ï¼š
- **åˆ†çº§æç¤º**ï¼šæŒ‰é‡è¦æ€§åˆ†å±‚ç»„ç»‡æ£€ç´¢å†…å®¹
- **ç»“æ„åŒ–è¾“å…¥**ï¼šå°†æ£€ç´¢ç»“æœæŒ‰ç±»å‹/ä¸»é¢˜ç»„ç»‡
- **å¤šèµ„æºèåˆ**ï¼šç»¼åˆä¸åŒæ¥æºçš„æ£€ç´¢ç»“æœ
- **å…ƒæ•°æ®å¼•å¯¼**ï¼šå°†æ–‡æ¡£å…ƒæ•°æ®çº³å…¥æç¤º

## ğŸ“Š å®é™…åº”ç”¨æ¡ˆä¾‹

### 1. ğŸ“± ä¼ä¸šçŸ¥è¯†åº“åŠ©æ‰‹

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
- ä¼ä¸šå†…éƒ¨æ–‡æ¡£æ™ºèƒ½æ£€ç´¢
- æ”¿ç­–ä¸æµç¨‹ç²¾å‡†è§£è¯»
- è·¨éƒ¨é—¨çŸ¥è¯†å…±äº«
- æ–°å‘˜å·¥åŸ¹è®­ä¸å¼•å¯¼

**æŠ€æœ¯å®ç°è¦ç‚¹**ï¼š
- ç»†ç²’åº¦è®¿é—®æ§åˆ¶
- æ•æ„Ÿä¿¡æ¯è¿‡æ»¤
- å¤šæºä¿¡æ¯æ•´åˆ
- å›ç­”æº¯æºèƒ½åŠ›

**å®æ–½æˆæ•ˆ**ï¼š
> "æŸå…¨çƒåˆ¶é€ ä¼ä¸šå®æ–½ä¼ä¸šçŸ¥è¯†åº“åŠ©æ‰‹åï¼Œå‘˜å·¥è·å–å†…éƒ¨ä¿¡æ¯çš„æ—¶é—´å¹³å‡ç¼©çŸ­äº†76%ï¼Œå®¢æœéƒ¨é—¨çš„é¦–æ¬¡è§£å†³ç‡æé«˜äº†24%ï¼Œæ–°å‘˜å·¥å…¥èŒåŸ¹è®­å‘¨æœŸä»3å‘¨ç¼©çŸ­åˆ°1.5å‘¨ã€‚"

### 2. ğŸ’¼ æ³•å¾‹æ™ºèƒ½é¡¾é—®

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
- æ³•å¾‹æ–‡æ¡£æ™ºèƒ½åˆ†æ
- æ¡ˆä¾‹æ£€ç´¢ä¸ç›¸å…³åº¦æ’åº
- æ³•è§„è§£è¯»ä¸åˆè§„å»ºè®®
- åˆåŒé£é™©è¯„ä¼°

**æŠ€æœ¯å®ç°**ï¼š
```python
def legal_research_assistant(query, legal_vectordb, llm):
    """æ³•å¾‹ç ”ç©¶åŠ©æ‰‹å®ç°"""
    # æŸ¥è¯¢é¢„å¤„ç†(å¢åŠ æ³•å¾‹æœ¯è¯­)
    enhanced_query = legal_query_enhancement(query)
    
    # å¤šé˜¶æ®µæ£€ç´¢
    legal_docs = legal_vectordb.similarity_search(
        enhanced_query, 
        k=7,
        filter={"jurisdiction": "é€‚ç”¨åŒºåŸŸ", "updated_after": "2022-01-01"}
    )
    
    # ç›¸å…³æ€§å†æ’åº
    ranked_docs = rerank_legal_docs(legal_docs, query, llm)
    
    # æ„å»ºæç¤º(åŒ…å«æ³•å¾‹å…è´£å£°æ˜)
    prompt = f"""
    ä½œä¸ºæ³•å¾‹ç ”ç©¶åŠ©æ‰‹ï¼Œè¯·åŸºäºä»¥ä¸‹æ³•å¾‹èµ„æ–™å›ç­”é—®é¢˜:
    
    é—®é¢˜: {query}
    
    å‚è€ƒèµ„æ–™:
    {format_legal_docs(ranked_docs)}
    
    è¯·è¯¦ç»†åˆ†æå¹¶ç»™å‡ºç­”æ¡ˆï¼Œå¼•ç”¨ç›¸å…³æ³•æ¡å’Œæ¡ˆä¾‹ã€‚
    å£°æ˜ï¼šæ­¤å›ç­”ä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæ³•å¾‹å»ºè®®ã€‚å…·ä½“æƒ…å†µè¯·å’¨è¯¢ä¸“ä¸šå¾‹å¸ˆã€‚
    """
    
    response = llm.generate(prompt, temperature=0.2)
    
    # æ·»åŠ å¼•ç”¨æ¥æº
    response_with_citations = add_legal_citations(response, ranked_docs)
    return response_with_citations
```

**åº”ç”¨æ•ˆæœ**ï¼š
> "å¾‹å¸ˆäº‹åŠ¡æ‰€æŠ¥å‘Šï¼Œä½¿ç”¨è¯¥ç³»ç»Ÿåï¼Œæ³•å¾‹ç ”ç©¶æ—¶é—´å‡å°‘äº†65%ï¼Œèµ„æ–™æ£€ç´¢è¦†ç›–ç‡æé«˜äº†83%ï¼Œä½¿å¾‹å¸ˆèƒ½å¤Ÿä¸“æ³¨äºæ›´é«˜ä»·å€¼çš„åˆ†æå’Œç­–ç•¥å·¥ä½œã€‚"

### 3. ğŸ¥ åŒ»ç–—çŸ¥è¯†åŠ©æ‰‹

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
- åŒ»å­¦æ–‡çŒ®æ™ºèƒ½æ£€ç´¢
- ç—…ä¾‹ç›¸ä¼¼æ¡ˆä¾‹åˆ†æ
- æ²»ç–—æ–¹æ¡ˆå‚è€ƒæ¨è
- è¯ç‰©ç›¸äº’ä½œç”¨æŸ¥è¯¢

**å®æ–½æ¶æ„**ï¼š
```
åŒ»å­¦æ–‡çŒ®åº“ â†’ ç»“æ„åŒ–æå– â†’ å®ä½“å…³ç³»å›¾è°± â†’ å¤šæ¨¡æ€ç´¢å¼• â†’ åŒ»å­¦LLM â†’ ä¸´åºŠå†³ç­–æ”¯æŒ
```

**å®‰å…¨ä¸è´£ä»»è®¾è®¡**ï¼š
- ä¸¥æ ¼çš„åŒ»å­¦å‡†ç¡®æ€§éªŒè¯
- å¤šçº§ä¸“ä¸šçŸ¥è¯†æ¥æºæ ‡æ³¨
- æ˜ç¡®çš„ä½¿ç”¨é™åˆ¶è¯´æ˜
- ä¸“ä¸šåŒ»ç”Ÿå®¡æ ¸æœºåˆ¶

## ğŸ› ï¸ è¯„ä¼°ä¸ä¼˜åŒ–

### 1. ğŸ¯ æ€§èƒ½è¯„ä¼°æŒ‡æ ‡

**å…³é”®è¯„ä¼°ç»´åº¦**ï¼š
- **ç›¸å…³æ€§**ï¼šæ£€ç´¢ç»“æœä¸é—®é¢˜çš„åŒ¹é…åº¦
- **å‡†ç¡®æ€§**ï¼šå›ç­”çš„äº‹å®æ­£ç¡®æ€§
- **å®Œæ•´æ€§**ï¼šå›ç­”è¦†ç›–é—®é¢˜çš„å…¨é¢ç¨‹åº¦
- **æ•ˆç‡**ï¼šæ£€ç´¢å’Œç”Ÿæˆçš„æ—¶é—´æ€§èƒ½
- **å¯é æ€§**ï¼šç³»ç»Ÿåœ¨å„ç§æŸ¥è¯¢ä¸‹çš„ä¸€è‡´è¡¨ç°

**è¯„ä¼°æ–¹æ³•ç¤ºä¾‹**ï¼š
```python
def evaluate_rag_system(system, test_dataset, ground_truth):
    """è¯„ä¼°RAGç³»ç»Ÿæ€§èƒ½"""
    metrics = {
        "relevance": [],
        "factual_accuracy": [],
        "answer_completeness": [],
        "retrieval_precision": [],
        "latency": []
    }
    
    for i, query in enumerate(test_dataset):
        start_time = time.time()
        
        # è·å–ç³»ç»Ÿå›ç­”
        retrieved_docs, answer = system.query(query)
        
        # è®¡ç®—å»¶è¿Ÿ
        latency = time.time() - start_time
        metrics["latency"].append(latency)
        
        # è¯„ä¼°æ£€ç´¢ç²¾åº¦
        relevant_docs = ground_truth[i]["relevant_docs"]
        retrieval_precision = calculate_precision(retrieved_docs, relevant_docs)
        metrics["retrieval_precision"].append(retrieval_precision)
        
        # è¯„ä¼°ç­”æ¡ˆè´¨é‡
        expected_answer = ground_truth[i]["answer"]
        metrics["factual_accuracy"].append(evaluate_factual_accuracy(answer, expected_answer))
        metrics["answer_completeness"].append(evaluate_completeness(answer, expected_answer))
        metrics["relevance"].append(evaluate_relevance(answer, query))
    
    # è®¡ç®—å¹³å‡æŒ‡æ ‡
    results = {k: sum(v)/len(v) for k, v in metrics.items()}
    return results
```

### 2. ğŸ”§ ç³»ç»Ÿä¼˜åŒ–æ–¹æ³•

**æ£€ç´¢ä¼˜åŒ–**ï¼š
- æé«˜åµŒå…¥è´¨é‡(ä¸“ä¸šåµŒå…¥æ¨¡å‹)
- ä¼˜åŒ–åˆ†å—ç­–ç•¥(è¯­ä¹‰å®Œæ•´æ€§)
- å®ç°æ··åˆæ£€ç´¢(è¯æ³•+è¯­ä¹‰)
- åŠ¨æ€è°ƒæ•´æ£€ç´¢æ•°é‡

**å›ç­”ç”Ÿæˆä¼˜åŒ–**ï¼š
```python
def optimized_rag_response(query, context_docs, llm):
    """ä¼˜åŒ–çš„RAGå›ç­”ç”Ÿæˆ"""
    # 1. ä¸Šä¸‹æ–‡æ•´åˆä¸æ’åº
    processed_context = []
    for doc in context_docs:
        # æå–æ–‡æ¡£å…³é”®æ®µè½
        key_passages = extract_key_passages(doc.page_content, query)
        # æ·»åŠ å…ƒæ•°æ®
        source_info = f"(æ¥æº: {doc.metadata.get('source', 'æœªçŸ¥')}, " \
                      f"æ—¥æœŸ: {doc.metadata.get('date', 'æœªçŸ¥')})"
        
        for passage in key_passages:
            processed_context.append(f"{passage} {source_info}")
    
    # 2. æ„å»ºå¢å¼ºæç¤º
    enhanced_prompt = f"""
    ä½œä¸ºçŸ¥è¯†åŠ©æ‰‹ï¼Œè¯·åŸºäºä»¥ä¸‹æä¾›çš„å‚è€ƒèµ„æ–™å›ç­”ç”¨æˆ·é—®é¢˜ã€‚
    å›ç­”åº”è¯¥å…¨é¢ã€å‡†ç¡®ï¼Œå¹¶é€‚å½“å¼•ç”¨æ¥æºã€‚
    å¦‚æœå‚è€ƒèµ„æ–™ä¸åŒ…å«ç­”æ¡ˆï¼Œè¯·æ¸…æ™°è¯´æ˜ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯ã€‚
    
    ç”¨æˆ·é—®é¢˜: {query}
    
    å‚è€ƒèµ„æ–™:
    {format_numbered_context(processed_context)}
    
    ç”Ÿæˆå›ç­”æ—¶ï¼Œè¯·:
    1. ç¡®ä¿å›ç­”ä¸é—®é¢˜ç›´æ¥ç›¸å…³
    2. é€»è¾‘æ¸…æ™°ï¼ŒæŒ‰é‡è¦æ€§ç»„ç»‡ä¿¡æ¯
    3. åœ¨é€‚å½“ä½ç½®å¼•ç”¨æ¥æºç¼–å·
    4. å¦‚æœ‰å¤šä¸ªè§‚ç‚¹ï¼Œè¯·å¯¹æ¯”è¯´æ˜
    """
    
    # 3. ç”Ÿæˆå›ç­”(é™ä½åˆ›é€ æ€§å‚æ•°)
    response = llm.generate(
        enhanced_prompt,
        temperature=0.2,
        top_p=0.85,
        max_tokens=800
    )
    
    return response
```

**ç”¨æˆ·ä½“éªŒä¼˜åŒ–**ï¼š
- å›ç­”ä¸­æ·»åŠ æ¥æºå¼•ç”¨
- ç»“æœç›¸å…³æ€§è§£é‡Š
- æä¾›æ›´å¤šä¿¡æ¯é€‰é¡¹
- ç”¨æˆ·åé¦ˆæ”¶é›†ä¸åº”ç”¨

## ğŸ”® æŠ€æœ¯å‘å±•è¶‹åŠ¿

### 1. ğŸ§  é€’å½’æ£€ç´¢ä¸æ¨ç†

**é«˜çº§æ£€ç´¢èŒƒå¼**ï¼š
- **å¤šæ­¥éª¤æ£€ç´¢**ï¼šå°†å¤æ‚æŸ¥è¯¢åˆ†è§£ä¸ºå¤šä¸ªå­æŸ¥è¯¢
- **é€’å½’RAG**ï¼šæ ¹æ®åˆå§‹ç»“æœç”Ÿæˆæ–°çš„æ£€ç´¢æŸ¥è¯¢
- **è‡ªæˆ‘åæ€æ£€ç´¢**ï¼šç³»ç»Ÿè‡ªè¯„ç»“æœè´¨é‡ï¼Œå†³å®šæ˜¯å¦éœ€è¦æ›´å¤šæ£€ç´¢

```python
def recursive_retrieval_rag(initial_query, vectordb, llm, max_iterations=3):
    """é€’å½’æ£€ç´¢RAGå®ç°"""
    all_retrieved_docs = []
    current_query = initial_query
    
    for i in range(max_iterations):
        # å½“å‰æŸ¥è¯¢çš„æ£€ç´¢
        current_docs = vectordb.similarity_search(current_query, k=3)
        all_retrieved_docs.extend(current_docs)
        
        # è¯„ä¼°å·²æ£€ç´¢ä¿¡æ¯æ˜¯å¦å……åˆ†
        evaluation_prompt = f"""
        åŸå§‹é—®é¢˜: {initial_query}
        
        å·²æ£€ç´¢ä¿¡æ¯:
        {format_docs(all_retrieved_docs)}
        
        è¯„ä¼°è¿™äº›ä¿¡æ¯æ˜¯å¦è¶³å¤Ÿå›ç­”åŸå§‹é—®é¢˜ã€‚
        å¦‚æœä¸å¤Ÿï¼Œè¯·æŒ‡å‡ºè¿˜éœ€è¦æ£€ç´¢å“ªäº›ä¿¡æ¯ï¼Œå¹¶ç»™å‡ºæ–°çš„æ£€ç´¢æŸ¥è¯¢ã€‚
        å¦‚æœå·²ç»è¶³å¤Ÿï¼Œè¯·å›å¤"ä¿¡æ¯å……åˆ†"ã€‚
        """
        
        evaluation = llm.generate(evaluation_prompt, temperature=0.3)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ç»§ç»­æ£€ç´¢
        if "ä¿¡æ¯å……åˆ†" in evaluation:
            break
            
        # æå–ä¸‹ä¸€æ­¥æ£€ç´¢æŸ¥è¯¢
        next_query_prompt = f"""
        åŸºäºä»¥ä¸‹è¯„ä¼°ï¼Œæå–ä¸€ä¸ªç”¨äºä¸‹ä¸€æ­¥æ£€ç´¢çš„æ¸…æ™°æŸ¥è¯¢ã€‚
        è¯„ä¼°: {evaluation}
        
        ä¸‹ä¸€æ­¥æ£€ç´¢æŸ¥è¯¢:
        """
        
        current_query = llm.generate(next_query_prompt, temperature=0.3)
    
    # ç”Ÿæˆæœ€ç»ˆå›ç­”
    final_response = generate_rag_response(initial_query, all_retrieved_docs, llm)
    return final_response
```

### 2. ğŸŒ å¤šæ¨¡æ€çŸ¥è¯†èåˆ

**è¶‹åŠ¿å‘å±•**ï¼š
- æ–‡æœ¬+å›¾åƒçŸ¥è¯†åº“é›†æˆ
- å›¾è¡¨å’Œå›¾å½¢æ•°æ®ç†è§£
- è§†é¢‘å†…å®¹ç´¢å¼•ä¸æ£€ç´¢
- ç»“æ„åŒ–+éç»“æ„åŒ–æ•°æ®èåˆ

**åº”ç”¨å‰æ™¯**ï¼š
- åŒ»ç–—å½±åƒ+ç—…å†æ–‡æœ¬åˆ†æ
- æŠ€æœ¯æ–‡æ¡£+å›¾è¡¨ç»¼åˆç†è§£
- æ•™è‚²å†…å®¹å¤šæ¨¡æ€è¾…åŠ©
- äº§å“çŸ¥è¯†åº“ä¸è§†è§‰æ£€ç´¢

### 3. ğŸ”„ çŸ¥è¯†åº“è‡ªæ›´æ–°æœºåˆ¶

**è‡ªåŠ¨åŒ–æ›´æ–°æ¶æ„**ï¼š
- å˜æ›´æ£€æµ‹ä¸å·®å¼‚è®¡ç®—
- å¢é‡æ›´æ–°ä¸ç»´æŠ¤
- çŸ¥è¯†ä¸€è‡´æ€§éªŒè¯
- è‡ªåŠ¨åŒ–é‡‡é›†ä¸å¤„ç†

**å‰æ²¿æŠ€æœ¯æ–¹å‘**ï¼š
- LLMè¾…åŠ©çŸ¥è¯†æå–ä¸å½’çº³
- çŸ¥è¯†å›¾è°±åŠ¨æ€ç»´æŠ¤
- åˆ†å¸ƒå¼çŸ¥è¯†ååŒæ›´æ–°
- ç”¨æˆ·äº¤äº’é©±åŠ¨çš„çŸ¥è¯†å¢å¼º

## ğŸ“š å¼€å‘èµ„æºæ¨è

### 1. ğŸ› ï¸ æ¨èå·¥å…·ä¸æ¡†æ¶

- [LangChain](https://github.com/langchain-ai/langchain) - RAGåº”ç”¨æ„å»ºæ¡†æ¶
- [LlamaIndex](https://github.com/jerryjliu/llama_index) - æ•°æ®æ¡†æ¶è¿æ¥LLM
- [Chroma](https://github.com/chroma-core/chroma) - å¼€æºå‘é‡æ•°æ®åº“
- [Haystack](https://github.com/deepset-ai/haystack) - ç”Ÿäº§çº§æœç´¢å’ŒRAGæ¡†æ¶

### 2. ğŸ“‘ å­¦ä¹ èµ„æº

- [RAGæ¶æ„è®¾è®¡æŒ‡å—](https://www.pinecone.io/learn/retrieval-augmented-generation)
- [å‘é‡æœç´¢å®æˆ˜](https://www.sbert.net/examples/applications/semantic-search/README.html)
- [æç¤ºå·¥ç¨‹è¿›é˜¶](https://www.promptingguide.ai/)
- [RAGç³»ç»Ÿè¯„ä¼°](https://arxiv.org/abs/2305.11747)

### 3. ğŸ§© å¼€æºé¡¹ç›®

- [GPT-RAG](https://github.com/Azure-Samples/azure-search-openai-demo) - Azure RAGç¤ºä¾‹
- [PrivateGPT](https://github.com/imartinez/privateGPT) - æœ¬åœ°ç§æœ‰æ–‡æ¡£é—®ç­”
- [Llama-Index-Guides](https://github.com/run-llama/llama-index/tree/main/docs)
- [Ragatouille](https://github.com/bclavie/ragatouille) - é«˜çº§RAGå®éªŒæ¡†æ¶ 