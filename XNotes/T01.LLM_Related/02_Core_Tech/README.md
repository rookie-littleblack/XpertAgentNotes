# ⚙️ 核心技术原理

## 子目录内容

1. 🏗️ [Transformer架构详解](transformer.md)
2. 👁️ [注意力机制深度解析](attention.md)
3. 🔄 [预训练方法与策略](pretraining.md)
4. ✏️ [提示工程技术](prompt_engineering.md)
5. 📊 [模型架构对比](architecture_comparison.md)

## 板块说明

本板块深入探讨大模型的核心技术原理，包括：
- Transformer架构的组成与原理
- 自注意力机制的数学原理与实现
- 各种预训练方法的优缺点
- 提示工程的技巧与方法
- 主流大模型架构的比较与分析

适合对大模型技术原理感兴趣的开发者、研究人员和学习者。本板块内容相对专业，建议具备基本的机器学习和深度学习知识。

## 学习建议

1. 先理解Transformer架构和注意力机制的基础知识
2. 然后学习预训练方法，了解模型如何获得基础能力
3. 最后学习提示工程和架构对比，掌握实际应用技巧
