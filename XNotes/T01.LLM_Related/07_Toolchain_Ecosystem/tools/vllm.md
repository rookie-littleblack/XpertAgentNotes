# vLLM

- **本质**：专注于大模型推理加速的高性能推理引擎。
- **特点**：  
  - 极致优化的推理吞吐量和并发能力（如PagedAttention、连续批处理等）。
  - 主要用于大规模生产部署和高并发场景。
  - 只专注于推理，不负责训练和微调。
- **归类**：**专用高性能推理引擎**。
