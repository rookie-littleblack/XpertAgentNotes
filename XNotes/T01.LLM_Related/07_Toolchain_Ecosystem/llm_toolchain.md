# å¤§æ¨¡å‹å·¥å…·é“¾ä¸ç”Ÿæ€ ğŸ› ï¸ğŸ”„

## 1. å¤§æ¨¡å‹å·¥å…·é“¾æ¦‚è¿° ğŸ“‹

å¤§æ¨¡å‹å·¥å…·é“¾æŒ‡çš„æ˜¯æ”¯æŒå¤§å‹è¯­è¨€æ¨¡å‹(LLM)å…¨ç”Ÿå‘½å‘¨æœŸçš„å·¥å…·ã€æ¡†æ¶å’Œå¹³å°çš„é›†åˆï¼Œä»æ•°æ®å‡†å¤‡ã€æ¨¡å‹è®­ç»ƒåˆ°éƒ¨ç½²åº”ç”¨ï¼Œå½¢æˆäº†ä¸€ä¸ªå®Œæ•´çš„æŠ€æœ¯ç”Ÿæ€ç³»ç»Ÿã€‚éšç€å¤§æ¨¡å‹æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼Œå›´ç»•LLMçš„å·¥å…·é“¾ç”Ÿæ€ä¹Ÿæ—¥ç›Šä¸°å¯Œå’Œæˆç†Ÿã€‚

### 1.1 å·¥å…·é“¾çš„ä»·å€¼ ğŸ’

- **é™ä½æŠ€æœ¯é—¨æ§›**ï¼šå·¥å…·é“¾ä½¿éä¸“ä¸šäººå‘˜ä¹Ÿèƒ½åˆ©ç”¨å¤§æ¨¡å‹æŠ€æœ¯
- **æé«˜å¼€å‘æ•ˆç‡**ï¼šæ ‡å‡†åŒ–æµç¨‹å’Œè‡ªåŠ¨åŒ–å·¥å…·å¤§å¹…å‡å°‘å¼€å‘æ—¶é—´
- **ä¼˜åŒ–èµ„æºåˆ©ç”¨**ï¼šåˆç†åˆ†é…è®¡ç®—èµ„æºï¼Œé™ä½éƒ¨ç½²æˆæœ¬
- **ä¿ƒè¿›åä½œåˆ›æ–°**ï¼šæä¾›ç»Ÿä¸€æ¥å£å’Œæ ‡å‡†ï¼Œä¿ƒè¿›å›¢é˜Ÿåä½œå’ŒæŠ€æœ¯åˆ›æ–°
- **åŠ é€Ÿåº”ç”¨è½åœ°**ï¼šç¼©çŸ­ä»æ¦‚å¿µåˆ°äº§å“çš„å‘¨æœŸï¼ŒåŠ é€Ÿå•†ä¸šåŒ–

### 1.2 å·¥å…·é“¾çš„å‘å±•è¶‹åŠ¿ ğŸ“ˆ

- **æ•´åˆåº¦æå‡**ï¼šä»åˆ†æ•£å·¥å…·åˆ°ä¸€ç«™å¼å¹³å°æ¼”è¿›
- **ä½ä»£ç /æ— ä»£ç åŒ–**ï¼šè§†è§‰åŒ–ç•Œé¢é™ä½ä½¿ç”¨é—¨æ§›
- **ä¸“ä¸šåŒ–åˆ†å·¥**ï¼šé’ˆå¯¹ç‰¹å®šä»»åŠ¡å’Œåœºæ™¯çš„ä¸“ä¸šå·¥å…·å¢å¤š
- **å¼€æºç”Ÿæ€ç¹è£**ï¼šå¼€æºé¡¹ç›®å¼•é¢†åˆ›æ–°ï¼Œå½¢æˆæ´»è·ƒç¤¾åŒº
- **è·¨å¹³å°å…¼å®¹æ€§**ï¼šæ”¯æŒå¤šç§ç¡¬ä»¶å’Œäº‘ç¯å¢ƒçš„éƒ¨ç½²é€‰é¡¹

## 2. å¤§æ¨¡å‹å¼€å‘å·¥å…·é“¾çš„ä¸»è¦ç»„ä»¶ ğŸ§©

### 2.1 æ•°æ®å¤„ç†å·¥å…· ğŸ“Š

#### 2.1.1 æ•°æ®æ”¶é›†ä¸æ ‡æ³¨å·¥å…·

- **[Label Studio](https://labelstud.io/)**ï¼šå¼€æºæ•°æ®æ ‡æ³¨å¹³å°ï¼Œæ”¯æŒæ–‡æœ¬ã€å›¾åƒç­‰å¤šæ¨¡æ€æ•°æ®
- **[Argilla](https://argilla.io/)**ï¼šé¢å‘LLMçš„æ•°æ®æ ‡æ³¨ä¸ç®¡ç†å·¥å…·
- **[Humanloop](https://humanloop.com/)**ï¼šä¸“æ³¨äºäººå·¥åé¦ˆæ”¶é›†å’ŒRLHFæ•°æ®ç®¡ç†

#### 2.1.2 æ•°æ®æ¸…æ´—ä¸é¢„å¤„ç†å·¥å…·

- **[DeepSpeed-MoD](https://github.com/microsoft/DeepSpeed-MoD)**ï¼šå¾®è½¯å¼€å‘çš„æ•°æ®æ¸…æ´—å·¥å…·
- **[DataPrep.rlhf](https://github.com/allenai/dataflow/)**ï¼šRLHFæ•°æ®é¢„å¤„ç†å·¥å…·é›†
- **[Cleanlab](https://cleanlab.ai/)**ï¼šè‡ªåŠ¨æ£€æµ‹å’Œä¿®å¤æ•°æ®é—®é¢˜

### 2.2 æ¨¡å‹è®­ç»ƒä¸å¾®è°ƒå·¥å…· ğŸ§ 

#### 2.2.1 é¢„è®­ç»ƒæ¡†æ¶

- **[LLaMA-Factory](tools/llama_factory.md)**ï¼šç»Ÿä¸€çš„å¤§æ¨¡å‹å¾®è°ƒæ¡†æ¶ [ğŸ”—](https://github.com/hiyouga/LLaMA-Factory) [ğŸ“š](https://llamafactory.readthedocs.io/)
- **[DeepSpeed](https://github.com/microsoft/DeepSpeed)**ï¼šå¾®è½¯å¼€å‘çš„åˆ†å¸ƒå¼è®­ç»ƒåŠ é€Ÿåº“
- **[Megatron-LM](https://github.com/NVIDIA/Megatron-LM)**ï¼šNVIDIAçš„å¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒæ¡†æ¶
- **[ColossalAI](https://colossalai.org/)**ï¼šæ”¯æŒå¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒçš„æ¡†æ¶

#### 2.2.2 å¾®è°ƒæ¡†æ¶

- **[LLaMA-Factory](tools/llama_factory.md)**ï¼šç»Ÿä¸€çš„å¤§æ¨¡å‹å¾®è°ƒæ¡†æ¶ [ğŸ”—](https://github.com/hiyouga/LLaMA-Factory) [ğŸ“š](https://llamafactory.readthedocs.io/)
- **[PEFT](https://github.com/huggingface/peft)**ï¼šå‚æ•°é«˜æ•ˆå¾®è°ƒåº“ï¼ŒåŒ…æ‹¬LoRAã€Adapterç­‰
- **[FastChat](https://github.com/lm-sys/FastChat)**ï¼šç”¨äºè®­ç»ƒå’Œè¯„ä¼°èŠå¤©æ¨¡å‹çš„æ¡†æ¶

### 2.3 æ¨¡å‹è¯„ä¼°ä¸ä¼˜åŒ–å·¥å…· ğŸ“

#### 2.3.1 è¯„ä¼°æ¡†æ¶

- **[HELM](https://crfm.stanford.edu/helm/)**ï¼šæ–¯å¦ç¦çš„ç»¼åˆè¯­è¨€æ¨¡å‹è¯„ä¼°å¹³å°
- **[LM-Evaluation-Harness](https://github.com/EleutherAI/lm-evaluation-harness)**ï¼šEleutherAIå¼€å‘çš„è¯„ä¼°å¥—ä»¶
- **[OpenAI Evals](https://github.com/openai/evals)**ï¼šOpenAIçš„æ¨¡å‹è¯„ä¼°æ¡†æ¶

#### 2.3.2 ä¼˜åŒ–å·¥å…·

- **[ONNX Runtime](https://onnxruntime.ai/)**ï¼šæ¨¡å‹ä¼˜åŒ–å’Œæ¨ç†åŠ é€Ÿæ¡†æ¶
- **[TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM)**ï¼šNVIDIAé’ˆå¯¹LLMçš„æ¨ç†ä¼˜åŒ–
- **[Optimum](https://huggingface.co/docs/optimum/)**ï¼šHuggingFaceçš„æ¨¡å‹ä¼˜åŒ–åº“

### 2.4 åº”ç”¨å¼€å‘ä¸éƒ¨ç½²å·¥å…· ğŸš€

#### 2.4.1 åº”ç”¨å¼€å‘æ¡†æ¶

- **[LangChain](https://langchain.com/)**ï¼šæ„å»ºåŸºäºLLMçš„åº”ç”¨çš„æ¡†æ¶
- **[LlamaIndex](https://www.llamaindex.ai/)**ï¼šè¿æ¥LLMå’Œå¤–éƒ¨æ•°æ®çš„æ¡†æ¶
- **[Semantic Kernel](https://github.com/microsoft/semantic-kernel)**ï¼šå¾®è½¯çš„AIåº”ç”¨å¼€å‘SDK

#### 2.4.2 æ¨ç†éƒ¨ç½²å·¥å…·

- **[vLLM](https://github.com/vllm-project/vllm)**ï¼šé«˜æ€§èƒ½LLMæ¨ç†å¼•æ“
- **[Text Generation Inference](https://github.com/huggingface/text-generation-inference)**ï¼šHuggingFaceçš„æ¨ç†æœåŠ¡
- **[OpenLLM](https://github.com/bentoml/OpenLLM)**ï¼šç”¨äºéƒ¨ç½²å’ŒæœåŠ¡LLMçš„å¼€æºå¹³å°

## 3. ä¸»æµç”Ÿæ€ç³»ç»Ÿå’Œå¹³å° ğŸŒ

### 3.1 ç»¼åˆå¹³å°

- **[HuggingFace](https://huggingface.co/)**ï¼šæœ€å¤§çš„AIæ¨¡å‹ç¤¾åŒºå’Œå·¥å…·é›†
  ```python
  from transformers import AutoModelForCausalLM, AutoTokenizer
  
  # åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
  model = AutoModelForCausalLM.from_pretrained("meta-llama/Llama-2-7b-chat-hf")
  tokenizer = AutoTokenizer.from_pretrained("meta-llama/Llama-2-7b-chat-hf")
  
  # ç”Ÿæˆæ–‡æœ¬
  inputs = tokenizer("å¦‚ä½•ä½¿ç”¨Hugging Faceå¹³å°?", return_tensors="pt")
  outputs = model.generate(**inputs, max_length=100)
  print(tokenizer.decode(outputs[0]))
  ```

- **[Cohere Platform](https://cohere.com/)**ï¼šä¼ä¸šçº§LLMå¹³å°
- **[Anthropic Claude](https://www.anthropic.com/)**ï¼šä¸“æ³¨å®‰å…¨æ€§çš„AIåŠ©æ‰‹å¹³å°

### 3.2 ä¸“ä¸šåŒ–å·¥å…·é“¾

- **[LLM Foundry](https://github.com/mosaicml/llm-foundry)**ï¼šMosaicMLé¢å‘ä¼ä¸šçš„è®­ç»ƒå·¥å…·é“¾
- **[H2O LLM Studio](https://github.com/h2oai/h2o-llmstudio)**ï¼šç«¯åˆ°ç«¯LLMå¾®è°ƒå¹³å°
- **[Nvidia NeMo](https://developer.nvidia.com/nemo)**ï¼šNVIDIAçš„ç«¯åˆ°ç«¯LLMå¼€å‘æ¡†æ¶

### 3.3 å¼€æºç”Ÿæ€ç³»ç»Ÿ

- **[LangChainç”Ÿæ€](https://python.langchain.com/docs/ecosystem)**ï¼šè¿æ¥å„ç§å·¥å…·å’ŒæœåŠ¡
  ```python
  from langchain.chains import RetrievalQA
  from langchain.vectorstores import Chroma
  from langchain.embeddings.openai import OpenAIEmbeddings
  from langchain.llms import OpenAI
  
  # åˆ›å»ºä¸€ä¸ªæ£€ç´¢é—®ç­”é“¾
  embeddings = OpenAIEmbeddings()
  vectorstore = Chroma("documents", embeddings)
  qa_chain = RetrievalQA.from_chain_type(
      llm=OpenAI(),
      chain_type="stuff",
      retriever=vectorstore.as_retriever()
  )
  
  # ä½¿ç”¨é“¾å›ç­”é—®é¢˜
  response = qa_chain.run("ä»€ä¹ˆæ˜¯å‘é‡æ•°æ®åº“?")
  print(response)
  ```

- **[LlamaIndexç”Ÿæ€](https://docs.llamaindex.ai/en/stable/)**ï¼šçŸ¥è¯†åº“å¢å¼ºåº”ç”¨
- **[BentoML](https://github.com/bentoml/BentoML)**ï¼šæ¨¡å‹éƒ¨ç½²å’ŒæœåŠ¡å¹³å°

## 4. å·¥å…·é“¾é›†æˆä¸æœ€ä½³å®è·µ ğŸ”§

### 4.1 ç«¯åˆ°ç«¯è§£å†³æ–¹æ¡ˆæ¶æ„

![LLMå·¥å…·é“¾æ¶æ„](https://picsum.photos/id/180/800/400)

#### åŸºæœ¬æ¶æ„ç»„ä»¶:

1. **æ•°æ®å±‚**ï¼šåŸå§‹æ•°æ®â†’é¢„å¤„ç†â†’ç‰¹å¾å·¥ç¨‹â†’è®­ç»ƒæ•°æ®
2. **æ¨¡å‹å±‚**ï¼šé¢„è®­ç»ƒâ†’SFTâ†’RLHFâ†’é‡åŒ–ä¼˜åŒ–
3. **æ¨ç†å±‚**ï¼šæ¨¡å‹æœåŠ¡â†’ç¼“å­˜â†’æ‰©å±•â†’ç›‘æ§
4. **åº”ç”¨å±‚**ï¼šRAGâ†’Agentâ†’å¯¹è¯å¼•æ“â†’ä¸šåŠ¡é›†æˆ

### 4.2 å·¥å…·é“¾é€‰æ‹©ç­–ç•¥

| ä½¿ç”¨åœºæ™¯ | æ¨èå·¥å…·ç»„åˆ | ä¼˜åŠ¿ |
|---------|------------|------|
| ä¼ä¸šçº§åº”ç”¨å¼€å‘ | HuggingFace + LangChain + vLLM | å…¨é¢ç”Ÿæ€ã€çµæ´»é›†æˆã€é«˜æ€§èƒ½ |
| ç ”ç©¶å®éªŒ | PEFT + LM-Evaluation-Harness | å¿«é€Ÿè¿­ä»£ã€å…¨é¢è¯„ä¼° |
| è½»é‡çº§éƒ¨ç½² | ONNX Runtime + BentoML | ä¼˜åŒ–æ€§èƒ½ã€ç®€åŒ–éƒ¨ç½² |
| çŸ¥è¯†å¯†é›†å‹åº”ç”¨ | LlamaIndex + ChromaDB + LangChain | çŸ¥è¯†å¢å¼ºã€çµæ´»æŸ¥è¯¢ |

### 4.3 å¸¸è§æŒ‘æˆ˜ä¸è§£å†³æ–¹æ¡ˆ

1. **è®¡ç®—èµ„æºé™åˆ¶**
   - è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨é‡åŒ–æŠ€æœ¯ã€å‚æ•°é«˜æ•ˆå¾®è°ƒã€æ¨¡å‹è’¸é¦

2. **æ•°æ®è´¨é‡ä¸éšç§**
   - è§£å†³æ–¹æ¡ˆï¼šæ•°æ®æ¸…æ´—å·¥å…·ã€åˆæˆæ•°æ®ç”Ÿæˆã€æœ¬åœ°éƒ¨ç½²

3. **å·¥å…·å…¼å®¹æ€§é—®é¢˜**
   - è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨ç»Ÿä¸€æ¥å£çš„æ¡†æ¶ï¼Œå¦‚LangChainæˆ–LlamaIndex

4. **æ€§èƒ½ç“¶é¢ˆ**
   - è§£å†³æ–¹æ¡ˆï¼šåˆ†å¸ƒå¼æ¨ç†ã€æ‰¹å¤„ç†ã€KVç¼“å­˜ä¼˜åŒ–

## 5. æ¡ˆä¾‹ç ”ç©¶ï¼šä¼ä¸šLLMåº”ç”¨å·¥å…·é“¾å®æ–½ ğŸ“’

### 5.1 å®¢æœæ™ºèƒ½åŒ–å‡çº§æ¡ˆä¾‹

**èƒŒæ™¯**ï¼šç”µå•†ä¼ä¸šéœ€è¦å‡çº§å®¢æœç³»ç»Ÿï¼Œæé«˜è‡ªåŠ¨åŒ–ç‡å’Œå®¢æˆ·æ»¡æ„åº¦

**å·¥å…·é“¾é€‰æ‹©**ï¼š
- æ•°æ®å¤„ç†ï¼šLabel Studio (å¯¹è¯æ ‡æ³¨) + DeepSpeed-MoD (æ•°æ®æ¸…æ´—)
- æ¨¡å‹é€‚é…ï¼šPEFT (LoRAå¾®è°ƒ) + ONNX Runtime (æ¨¡å‹ä¼˜åŒ–)
- åº”ç”¨å¼€å‘ï¼šLangChain (ä¸šåŠ¡é€»è¾‘) + ChromaDB (çŸ¥è¯†åº“)
- éƒ¨ç½²æœåŠ¡ï¼švLLM (æ¨ç†å¼•æ“) + BentoML (æœåŠ¡åŒ–)

**æ•ˆæœ**ï¼š
- è‡ªåŠ¨åŒ–ç‡æå‡40%
- å¹³å‡å“åº”æ—¶é—´é™ä½65%
- å®¢æˆ·æ»¡æ„åº¦æå‡18%

### 5.2 å®æ–½æ­¥éª¤è¯¦è§£

```python
# ç¤ºä¾‹ï¼šå®¢æœç³»ç»Ÿé›†æˆLLMçš„ç®€åŒ–å®ç°

# 1. å¯¼å…¥ç›¸å…³åº“
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.document_loaders import DirectoryLoader
from langchain.llms import HuggingFacePipeline
from langchain.chains import ConversationalRetrievalChain
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline

# 2. å‡†å¤‡çŸ¥è¯†åº“
loader = DirectoryLoader("./customer_service_docs/", glob="**/*.txt")
documents = loader.load()
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
splits = text_splitter.split_documents(documents)

# 3. åˆ›å»ºå‘é‡å­˜å‚¨
embeddings = HuggingFaceEmbeddings(model_name="moka-ai/m3e-base")
vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)

# 4. åŠ è½½æ¨¡å‹
model_id = "THUDM/chatglm3-6b"
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(model_id)
pipe = pipeline("text-generation", model=model, tokenizer=tokenizer, max_length=2048)
llm = HuggingFacePipeline(pipeline=pipe)

# 5. åˆ›å»ºå¯¹è¯æ£€ç´¢é“¾
qa = ConversationalRetrievalChain.from_llm(
    llm=llm,
    retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
    return_source_documents=True
)

# 6. å®¢æœå¯¹è¯å¤„ç†
def process_customer_query(query, chat_history=[]):
    result = qa({"question": query, "chat_history": chat_history})
    return result["answer"], result["source_documents"]
```

## 6. æœªæ¥å‘å±•ä¸è¶‹åŠ¿ ğŸ”®

### 6.1 å·¥å…·é“¾å‘å±•è¶‹åŠ¿

- **è‡ªåŠ¨åŒ–ç¨‹åº¦æå‡**ï¼šAutoMLæ‰©å±•åˆ°LLMé¢†åŸŸï¼Œè‡ªåŠ¨åŒ–æ¨¡å‹é€‰æ‹©å’Œå‚æ•°è°ƒä¼˜
- **å¤šæ¨¡æ€æ•´åˆ**ï¼šå·¥å…·é“¾å°†æ”¯æŒæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘çš„ç»Ÿä¸€å¤„ç†
- **å‚ç›´é¢†åŸŸä¸“ç²¾**ï¼šé’ˆå¯¹é‡‘èã€åŒ»ç–—ã€æ³•å¾‹ç­‰é¢†åŸŸçš„ä¸“ä¸šå·¥å…·é“¾
- **è¾¹ç¼˜è®¡ç®—æ”¯æŒ**ï¼šä¼˜åŒ–å·¥å…·é€‚é…è¾¹ç¼˜è®¾å¤‡ï¼Œå®ç°æœ¬åœ°åŒ–éƒ¨ç½²

### 6.2 å…³é”®æŠ€æœ¯çªç ´ç‚¹

- **é«˜æ•ˆè®­ç»ƒæŠ€æœ¯**ï¼šæ›´é«˜æ•ˆçš„å¤§æ¨¡å‹è®­ç»ƒå’Œå¾®è°ƒæ–¹æ³•
- **è‡ªåŠ¨è¯„ä¼°ç³»ç»Ÿ**ï¼šç«¯åˆ°ç«¯çš„è¯„ä¼°å’Œåé¦ˆå¾ªç¯
- **çŸ¥è¯†å›¾è°±é›†æˆ**ï¼šç»“æ„åŒ–çŸ¥è¯†ä¸å¤§æ¨¡å‹çš„æ·±åº¦èåˆ
- **å®‰å…¨ä¸éšç§å·¥å…·**ï¼šå¢å¼ºå¯¹æ•æ„Ÿæ•°æ®çš„ä¿æŠ¤èƒ½åŠ›

## 7. å­¦ä¹ èµ„æºä¸ç¤¾åŒº ğŸ“š

### 7.1 å­¦ä¹ è·¯å¾„æ¨è

**å…¥é—¨çº§**ï¼š
- [HuggingFaceè¯¾ç¨‹](https://huggingface.co/learn)
- [LangChainæ–‡æ¡£](https://python.langchain.com/docs/get_started)
- [LlamaIndexæ•™ç¨‹](https://docs.llamaindex.ai/en/stable/getting_started/starter_example.html)

**è¿›é˜¶çº§**ï¼š
- [DeepLearning.AI LLMä¸“é¡¹è¯¾ç¨‹](https://www.deeplearning.ai/short-courses/)
- [Full Stack LLM Bootcamp](https://fullstackdeeplearning.com/llm-bootcamp/)
- [LLMä»é›¶åˆ°ä¸€å®æˆ˜è¯¾ç¨‹](https://github.com/datawhalechina/prompt-engineering-for-developers)

### 7.2 æ´»è·ƒç¤¾åŒº

- **GitHubç»„ç»‡**ï¼šHuggingFaceã€LangChainã€EleutherAI
- **Discordç¤¾åŒº**ï¼šLangChain Discordã€HuggingFace Discord
- **è®ºå›**ï¼šLLM Pulseè®ºå›ã€AI Alignmentè®ºå›

## 8. æ€»ç»“ ğŸ“

å¤§æ¨¡å‹å·¥å…·é“¾ä¸ç”Ÿæ€ç³»ç»Ÿçš„ç¹è£å‘å±•ä¸ºAIåº”ç”¨åˆ›æ–°æä¾›äº†å¼ºå¤§æ”¯æŒã€‚é€šè¿‡åˆç†é€‰æ‹©å’Œé›†æˆé€‚åˆçš„å·¥å…·é“¾ç»„ä»¶ï¼Œå¼€å‘è€…å¯ä»¥æ˜¾è‘—é™ä½å¤§æ¨¡å‹åº”ç”¨çš„å¼€å‘é—¨æ§›å’Œæˆæœ¬ï¼ŒåŠ é€ŸAIè§£å†³æ–¹æ¡ˆçš„è½åœ°ã€‚éšç€æŠ€æœ¯çš„ä¸æ–­æ¼”è¿›ï¼Œå·¥å…·é“¾å°†æ›´åŠ æ™ºèƒ½åŒ–ã€è‡ªåŠ¨åŒ–ï¼Œè¿›ä¸€æ­¥æ¨åŠ¨å¤§æ¨¡å‹æŠ€æœ¯çš„æ™®åŠå’Œåº”ç”¨ä»·å€¼çš„é‡Šæ”¾ã€‚

æ— è®ºæ˜¯ç ”ç©¶äººå‘˜ã€å¼€å‘è€…è¿˜æ˜¯ä¼ä¸šå†³ç­–è€…ï¼Œäº†è§£å’ŒæŒæ¡å¤§æ¨¡å‹å·¥å…·é“¾ç”Ÿæ€æ˜¯æŠŠæ¡AIæŠ€æœ¯å‘å±•æ–¹å‘å’Œåº”ç”¨æ½œåŠ›çš„å…³é”®ã€‚é€šè¿‡æŒç»­å­¦ä¹ å’Œå®è·µï¼Œæˆ‘ä»¬å¯ä»¥æ›´å¥½åœ°åˆ©ç”¨è¿™äº›å·¥å…·ï¼Œæ„å»ºæ›´æ™ºèƒ½ã€æ›´æœ‰ä»·å€¼çš„AIåº”ç”¨ã€‚ 